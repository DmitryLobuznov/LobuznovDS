{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Урок: Особенности работы с деревянными моделями. YETIRANK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Импорт библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "import torch\n",
    "from torch import Tensor, FloatTensor\n",
    "# Data\n",
    "from catboost.datasets import msrank_10k\n",
    "# Data preparation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Hyperparameter tuning\n",
    "import hyperopt as hopt\n",
    "from hyperopt import hp\n",
    "# Save model\n",
    "import pickle\n",
    "# Typing annotation\n",
    "from typing import (\n",
    "    Tuple, List, Dict, \n",
    "    Any, Union, Optional, \n",
    "    Callable, Iterable\n",
    ")\n",
    "# Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import json\n",
    "# Time management\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plot_config\n",
    "# Metrics\n",
    "from metrics import compute_gain, dcg, ndcg, ndcg_k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RankNet`: Проблемы подхода"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RankNet` представляет собой реализацию _Pairwise_ подхода к обучению моделей ранжирования. Модели с этим подходом занимаются `упорядочиванием пар документов` или `минимизацией числа попарных ошибок`.\n",
    "\n",
    "С одной стороны, перечисленные действия связаны с задачей ранжирования, однако легко привести пример, где минимизация попарных ошибок не улучшает метрики:\n",
    "\n",
    "|$List_1$|$List_2$|\n",
    "|:--:|:--:|\n",
    "|$rel_1$|-|\n",
    "|-|-|\n",
    "|-|$rel_1$|\n",
    "|-|$rel_2$|\n",
    "|-|-|\n",
    "|-|-|\n",
    "|-|-|\n",
    "|$rel_2$|-|\n",
    "\n",
    "Пусть у нас имеется 2 списка из 8 документов для упорядочивания, причём в каждом списке только 2 релевантных документа.\n",
    "\n",
    "Посчитаем _количество неупорядоченных пар_ и следующие метрики:\n",
    "* `Average Precision`;\n",
    "* `DCG`;\n",
    "* `WTA` (Winner Takes All).\n",
    "\n",
    "\n",
    "\n",
    "|Metric|$List_1$|$List_2$|\n",
    "|:--|:--:|:--:|\n",
    "|_Количество неупорядоченных пар_|6|<span style=\"background-color: green\">4</span>|\n",
    "|_AP_|5/2|<span style=\"background-color: red\">5/12</span>|\n",
    "|_DCG_|1.33|<span style=\"background-color: red\">0.931</span>|\n",
    "|_WTA_|1|<span style=\"background-color: red\">0</span>|\n",
    "\n",
    "Одной из причин, почему `RankNet` приводит к такой деградации метрик, является тот факт, что мы не учитываем важность документов: `некоторые из них куда важнее отранжировать в первую очередь`. В идеале нам бы хотелось, чтобы _вес документа зависел от того, как сильно изменится целевая метрика от перестановки конкретного объекта._\n",
    "\n",
    "Возможные пути решения этой проблемы:\n",
    "\n",
    "1. Перевзвешивать пары при расчёте функции потерь;\n",
    "2. Изменять функцию потерь путём внесения информации о целевой метрике;\n",
    "3. Менять градиент функции пропорционально целевой метрике.\n",
    "\n",
    "Именно последний подход был предложен авторами [LambdaRank](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/lambdarank.pdf)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LambdaRank`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним ещё один факт о `RankNet`. Данная модель использует кросс-энтропию $C$ в качестве функции потерь,\n",
    "$$\n",
    "    C = -\\sum_{x \\in X} p(x) \\cdot log(q(x))\n",
    "$$\n",
    "\n",
    "Также вспомним некоторые обозначения:\n",
    "* $s_i, s_j -$ предсказания релевантности для $i$-ого, $j$-ого докуметов;\n",
    "* $\\sigma(x) -$ любая монотонно возрастающая, положительная функция, в нашем случае - `сигмоида`;\n",
    "* $S_{ij} -$ новое трансформированное значение целевой переменной (target), получающееся в результате линейного преобразования старых значений: $\\{0, 0.5, 1\\}, \\to \\{-1, 0, 1\\}$\n",
    "$$\\overline{P}_{ij} = \\frac{1}{2}(1 + S_{ij})$$\n",
    "\n",
    "Рассмотрим, как выглядят `градиенты функции потерь` $C$ `по предсказанным значениям релевантностей`$s_i$. Можно заметить, что значение совпадает для $i$-ого и $j$-ого документа с точностью до знака, что вполне логично: пара документов, которые неправильно отранжированны относительно друг друга, должны \"тянуться\" в разные стороны с одинаковой \"силой\" в силу симметричности:\n",
    "$$\n",
    "    \\frac{\\partial{C}}{\\partial{s_i}} = \\sigma \\left( \\frac{1}{2}(1 - S_{ij}) - \\frac{1}{1 + e^{\\sigma(s_i - s_j)}} \\right) = -\\frac{\\partial{C}}{\\partial{s_j}}\n",
    "$$\n",
    "\n",
    "Стоит заметить, что в формуле сверху рассматриваются градиенты относительно предсказаний $s$, а не весов самой модели RankNet. Поэтому давайте теперь рассмотрим полную формулу уже относительно весов нашей модели:\n",
    "$$\n",
    "    \\frac{\\partial{C}}{\\partial{w_{k}}} = \\frac{\\partial{C}}{\\partial {s_{i}}} \\frac{\\partial {s_{i}}}{\\partial w_{k}} + \\frac{\\partial C}{\\partial s_{j}} \\frac{\\partial s_{j}}{\\partial w_{k}} = \\sigma \\left( \\frac{1}{2} \\left(1-S_{i j} \\right) - \\frac{1}{1+e^{\\sigma \\left( s_{i}-s_{j} \\right) }} \\right) \\left( \\frac{\\partial s_{i}}{\\partial w_{k}} - \\frac{\\partial s_{j}}{\\partial w_{k}} \\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой формуле фигурирует уже знакомая нам дробь, которую мы рассматривали в формуле выше. Мы можем произвести замену, после чего вынести общую часть за скобки. В результате у нас получается произведение из двух множителей: в первых скобках у нас записано выражение, характеризующее `целевое изменение предсказаний` модели, а во вторых — `градиенты для изменения весов` модели.\n",
    "\n",
    "Далее для простоты и краткости весь первый множитель этого произведения обозначим как $\\lambda_{ij}$\n",
    "$$\n",
    "    \\lambda_{ij} \\equiv \\frac {\\partial C(s_i - s_j)}{s_i} = \\sigma\\left( \\frac{1}{2} \\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{\\sigma(s_i - s_j)}}\\right)\n",
    "$$\n",
    "\n",
    "Тогда получим более лаконичнуб запись формулы для градиентов весов модели:\n",
    "$$\n",
    "    \\sigma\\left( \\frac{1}{2} \\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{\\sigma(s_i - s_j)}}\\right) \\left(\\frac{\\partial s_{i}}{\\partial w_{k}} - \\frac{\\partial s_{j}}{\\partial w_{k}} \\right) = \\lambda_{ij} \\left(\\frac{\\partial s_{i}}{\\partial w_{k}} - \\frac{\\partial s_{j}}{\\partial w_{k}} \\right)\n",
    "$$\n",
    "\n",
    "Далее, не ограничивая общности случая, переупорядочим все пары предсказанных релевантностей так, чтобы $i$-ый документ был всегда более релевантен чем $j$-ый документ. Тогда формула ещё сократится, т.к $S_{ij}=1$:\n",
    "$$\n",
    "    \\lambda_{ij} = \\frac{\\partial C (s_i - s_j)}{\\partial s_i} = -\\sigma \\left( \\frac{1}{1 + e^{\\sigma(s_i - s_j)}} \\right)\n",
    "$$\n",
    "\n",
    "> А для чего собственно это было нужно?\n",
    "\n",
    "Теперь можно заметить, что $\\lambda_{ij}$ зависят только от наших предсказаний релевантностей $s_i, s_j$ и не зависят от функции потерь => мы больше не ограничены в выборе функции для $\\lambda$. Она может быть сколь угодно сложной функцией. Это позволяет обойти трудности, связанные с сортировкой в большинстве метрик для задач ранжирования и $IR$ (_Information Retrieval_), и напрямую работать с их оптимизацией, а не ограничиваться корректным упорядочиванием пар."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда формула для обновления весов модели получается следующей:\n",
    "$$\n",
    "    \\delta w_k = \\eta \\sum_{\\{i,j\\} \\in I} \\left( \\lambda_{ij}\\frac{\\partial{s_i}}{\\partial w_k} - \\lambda_{ij} \\frac{\\partial s_j}{\\partial w_k} \\right) = \\eta \\sum_{\\{i,j\\} \\in I} \\lambda_{i}\\frac{\\partial s_i}{\\partial w_k}\n",
    "$$\n",
    "\n",
    "Здесь за $\\lambda_i$ обозначена сумма по всем парам в датасете, в которые входит $i$-й элемент:\n",
    "\n",
    "$\\lambda_{i}=\\sum_{j:\\{i, j\\} \\in I} \\lambda_{i j}-\\sum_{j:\\{j, i\\} \\in I} \\lambda_{i j}$\n",
    "\n",
    "Здесь очень просто провести аналогию с миром физики. Наш $i$-й документ можно представить как некоторую массу. Каждый $j$-й документ в первой сумме при вычислении $\\lambda_i $— это по сути маленькая сила, которая подталкивает наш документ вверх или вниз в списке выдачи, повышая или понижая его предсказанное значение релевантности.\n",
    "\n",
    "![https://storage.yandexcloud.net/klms-public/production/learning-content/3/10/161/535/3594/image.png](https://storage.yandexcloud.net/klms-public/production/learning-content/3/10/161/535/3594/image.png)\n",
    "\n",
    "Сначала берём документы ниже нашего $i$-го в выдаче, т.е. где он является первым в паре (первая сумма в $\\lambda_i$). Это будут \"поднимающие\" силы, которые тянут документ вверх. Затем наоборот — документы выше нашего $i$-го в выдаче (вторая сумма в $\\lambda_i$). И это противодействующие силы, которые занижают наше предсказание релевантности. Сумма по всем таким объектам и есть суммарное воздействие на наш объект. Таким образом мы понимаем, как нужно изменять его оценку."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же посмотреть, как выбирают значение $\\lambda_i$ в реальной жизни, то на практике значение уже знакомой нам $\\lambda_i$ домножают на значение изменения целевой метрики, например nDCG (тут она немного модифицирована: вместо gain в числителе стоит степенная функция от него).\n",
    "\n",
    "$$\n",
    "    \\mathrm{DCG}= \\sum_{i} \\dfrac{2^{\\mathrm{rel}_{i}}-1}{\\log _{2}(i+1)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\mathrm{nDCG}=\\dfrac{\\mathrm{DCG}}{\\mathrm{IDCG}}\n",
    "$$\n",
    "\n",
    "Если же рассмотреть, как изменится метрика от перемены мест $i$-го и $j$-го документов, то мы получим следующую формулу:\n",
    "\n",
    "$$\n",
    "    \\lambda_{ij}=N\\left(\\dfrac{1}{1+e^{s_{i}-s_{j}}}\\right)\\left(2^{\\mathrm{rel}_{i}}-2^{\\mathrm{rel}_{j}}\\right)\\left(\\dfrac{1}{\\log_2 (i+1)}-\\dfrac{1}{\\log_2 (j+1)}\\right)\n",
    "$$\n",
    "\n",
    "Грубо говоря, чем больше прирост метрики от повышения или понижения позиции в ранжировании, тем больше это влияет на изменение предсказаний модели. В итоге более релевантные документы давят сверху, заставляя нерелевантные опускаться вниз, а менее релевантные давят снизу, заставляя всплывать подходящие документы.\n",
    "\n",
    "Важно отметить, что расчёт градиентов идёт уже после сортировки документов по оценкам и градиенты текут как будто бы от нашей метрики, от nDCG или другой. То есть мы сначала берём все документы для запроса, прогоняем их через модель и получаем предсказания релевантности каждого отдельного объекта. До этого момента метод напоминает pointwise-подход. Далее мы берём все пары из этого ранжирования и пытаемся оценить изменение метрики при перестановке этих двух объектов из пары. После этого для каждого документа рассчитываем суммарную лямбду, которая говорит о том, куда нам лучше направить изменение предсказаний — вверх или вниз.\n",
    "\n",
    "Трюк с вынесением $\\lambda_i$ в выражении называется факторизацией. За счёт него мы получаем выигрыш в скорости работы, так как он позволяет нам за один прогон (за один forward-pass) по модели получить все предсказания для выдачи, подсчитать $\\lambda_i$ и только после этого делать backward-pass (backpropagation), то есть операцию обратного распространения ошибки для расчёта градиентов. Этот шаг очень дорогой с точки зрения вычислительных мощностей. Если раньше для $n$ документов мы получали квадратичную зависимость от числа пар документов в датасете, то теперь мы используем пары для дешёвого расчёта изменения nDCG, а расчёт градиентов происходит один раз на каждый документ, на каждую $\\lambda_i$. Это привело к очень значительному ускорению обучения RankNet. Фактически время обучения упало с почти квадратичного по количеству релевантных документов на запрос до почти линейного."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MART`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Multiple Additive Regression Trees` - бустинг регрессионных деревьев.\n",
    "\n",
    "Рассмотрим вкратце алгоритм построения регрессионных деревьев:\n",
    "\n",
    "Пусть в некоторый момент построения мы имеем некоторую выборку объектов с их собственным набором признаков, представленных вектором. Для каждого признака:\n",
    "\n",
    "1. Переберём все значения этого признака и будем строить разбиение объектов простым условием: значение признака $j$ меньше некоторого порогового числа $k$. Если это условие выполняется, то объект попадает в левое поддерево, если же оно ошибочно — в правое.\n",
    "2. Затем по всем объектам левого поддерева L и правого R мы рассчитываем среднее значение предсказываемого значения $\\mu$.\n",
    "3. В каждом из двух множеств считаем среднеквадратичное отклонение (СКО). Общее СКО $S_j$ считаем как сумму СКО в левом и правом множествах.\n",
    "4. Затем среди всех перебранных комбинаций разбиений мы выбираем разбиение с наименьшим значением этого среднеквадратичного отклонения $S_j$.\n",
    "\n",
    "Функция ошибки может быть другой, но в классических деревьях для задачи регрессии используется именно СКО (_среднеквадратичное отклонение_).\n",
    "$$\n",
    "    S_j = \\sum_{i \\in L} (y_i - \\mu_L)^2 + \\sum_{i \\in L} (y_i - \\mu_R)^2\n",
    "$$\n",
    "\n",
    "Далее мы рекурсивно повторяем наш алгоритм для левого и правого поддерева, пока не достигнем некоторого критерия остановки, например _максимальной глубины дерева_, _максимального количества объектов в листе_ и т.д. Для самого последнего уровня дерева (или правильнее сказать _терминальных нод_), мы определяем наше предсказание как среднее всех объектов, попавших в лист дерева.\n",
    "\n",
    "`Градиентный бустинг` - один из способов построения ансамбля $F_N(x)$ решающих деревьев. Для его построения мы используем ансамбль последовательно обучаемых деревьев $f_i(x)$, предсказание каждого из которых входит в итоговую сумму предсказаний c некоторым весом $\\alpha_i$. Этот вес определяется каким-нибудь итеративным оптимизационным алгоритмом.\n",
    "$$\n",
    "    F_N(x) = \\sum_{i=1}^{N} \\alpha_i f_i(x)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть на каком-то этапе у нас есть некоторое количество построенных деревьев. \n",
    "> Как учить следующее?\n",
    "\n",
    "На текущей итерации строится $m$-ое дерево, когда на вход приходит суммарное предсказание $m-1$ предыдущих деревьев.\n",
    "\n",
    "Теперь необходимо понять, какие ответы должны получиться на следующем дереве, чтобы в сумме с текущими ответами наша ошибка минимизировалась. В этом нам поможет _антиградиент_, т.к. решается задача минимизации. Мы хотим понять, как нам нужно изменить наше предсказание на объекте, чтобы минимизировать некоторый функционал $L$ от целевой переменной $y_i$ и текущего предсказания $F_{m-1}(x_i)$. То есть по сути это как раз ровно такая производная, что указана в формуле ниже — наш антиградиент.\n",
    "\n",
    "$\\bar{y}_{i}=-\\left[\\dfrac{\\partial L\\left(y_{i}, F\\left(x_{i}\\right)\\right.}{\\partial F\\left(x_{i}\\right)}\\right]_{F(x)=F_{m-1}(x)}$\n",
    "\n",
    "Такое новое дерево должно корректировать уже имеющиеся предсказания, и потому ему на вход в качестве целевых переменных, в качестве меток, приходят не наши базовые $y_i$ из выборки, а так называемые \"невязки\" или остатки (сколько нам не хватает для того, чтобы дать точное предсказание).\n",
    "\n",
    "**Обратим внимание, что по сути это в точности наши $\\lambda_i$ из LambdaRank, из метода для задачи ранжирования!**\n",
    "\n",
    "$\\lambda_{i} \\equiv \\sum_{j \\in P_{i}} \\dfrac{\\partial C\\left(s_{i}, s_{j}\\right)}{\\partial s_{i}}$\n",
    "\n",
    "Естественным образом напрашивается объединение алгоритма LambdaRank и MART. Получается [LambdaMART](https://www.notion.so/learning/3/module/10/lesson/161/535/3596/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LambdaMART`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим получившийся алгоритм Lambda[S]MART:\n",
    "\n",
    "![Псевдокод алгоритма LambdaSMART](https://storage.yandexcloud.net/klms-public/production/learning-content/3/10/161/535/3596/image.png)\n",
    "\n",
    "Псевдокод алгоритма Lambda[S]MART\n",
    "\n",
    "- [2] Итак, сначала для всех $N$ объектов выборки получим входные предсказания. Это могут быть предсказания, например, ListNet или RankNet.\n",
    "- [4] Затем мы начинаем цикл постройки $M$  деревьев.\n",
    "- [5-6] Снова пройдёмся по всем объектам $N$ и для каждого посчитаем наш градиент. Если при построении классического градиентного бустинга мы использовали производную от функции MSE, которая равняется простой разности величин $y_i - f(x_i)$, то теперь мы считаем $\\lambda_i$, как это делалось в LambdaRank. На основе текущих предсказаний мы строим ранжирование, определяем прирост метрик от перестановки, рассматриваем все пары в выдаче и суммируем, чтобы получить финальное значение. Напомним, что смысл этой $\\lambda_i$ в том, что она указывает, как и в каком направлении нужно изменить наше предсказание, чтобы оптимизировать функцию ошибки или улучшить метрики.\n",
    "- [7] Тут же рассчитывается $w_i$ — вторая производная, используемая для расчёта веса при суммировании. Её мы опустим, так как к ранжированию это не имеет никакого отношения, это компонента градиентного бустинга.\n",
    "- [9] После того, как мы посчитали все $\\lambda_i$, мы их объявляем нашими целевыми переменными для построения нового дерева, и строим его для наших объектов $\\{x_i\\}_{i=1}^N$ с целью предсказать $\\lambda_i$, то есть новый $y_i$. Если в классическом градиентном бустинге в задаче регрессии мы брали разницу целевого и предсказанного значения, то сейчас мы пытаемся обучиться, используя $\\lambda_i$ в качестве целевой переменной, которая при построении каждого нового дерева меняется, так как меняются предсказанные значения. Эта замена производных работает потому, что и $\\lambda_i$, и разность указывают нам на то, как именно нужно поменять предсказываемые релевантности, чтобы уменьшить значение функции потерь.\n",
    "- [10] Далее рассчитываем длину нашего градиентного шага, которая уникальна для каждого отдельного листа. Это не learning rate, это отдельный коэффициент. Он вычисляется с помощью метода Ньютона (детали мы опустим). Суть в том, что просто подбирается такое число, при умножении на которое предсказаний нового построенного дерева мы, насколько это возможно, минимизируем функцию потерь.\n",
    "- [11] И наконец, мы обновляем наш ансамбль, добавляя к уже полученным скорам предсказания нового дерева. При этом здесь есть и learning rate, который обозначен как $v$ и обычно одинаков для всех деревьев в бустинге, и наш коэффициент, рассчитанный для каждого отдельного листа каждого отдельного дерева."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `YetiRank`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на оригинальную статью для интересующихся: [тут](http://proceedings.mlr.press/v14/gulin11a/gulin11a.pdf)\n",
    "\n",
    "Сейчас YetiRank широко используется, например, в CatBoost’е — реализации градиентного бустинга от Yandex. Разработан сам метод тоже сотрудниками Яндекса. На одной из страниц документации к CatBoost’у указывается, что он один из самых качественных с точки зрения средних метрик на разных датасетах. Однако он достаточно медленный. Интересно, что именно YetiRank выиграл те же соревнования, что и LambdaMART, но годом позже — в 2011 году.\n",
    "\n",
    "Итак, в качестве основной функции потерь используется та же самая формула, что была и в RankNet при pairwise-подходе, однако каждая пара дополнительно взвешивается множителем $w_{ij}$. Авторы также упоминают возможность добавления уже изученной нами $\\lambda_{i}$ при расчёте градиентов, но мы абстрагируемся от этого и сделаем упор на ключевых изменениях.\n",
    "\n",
    "$\\mathbb{L}=-\\sum_{(i, j)} w_{i j} \\log \\dfrac{e^{x_{i}}}{e^{x_{i}}+e^{x_{j}}}$\n",
    "\n",
    "$w_{ij} = N_{ij} c(l_i, l_j)$\n",
    "\n",
    "Каждый из весов уникален для конкретной пары документов при обучении и состоит из двух компонент, двух сомножителей. Первый множитель $N_{ij}$ помогает нам при обучении понять, насколько данная пара важна для ранжирования. Второй множитель — некоторая функция отметок релевантности $l_i$ и $l_j$ из разметки. Она показывает нам, насколько легко эти метки перепутать.\n",
    "\n",
    "Давайте внимательно рассмотрим первую составляющую. Как уже обсуждалось, не все объекты важны при ранжировании, и иногда лучше определённый документ поднимать со дна выдачи. Для оценки важности предлагается на очередной итерации бустинга брать предсказываемые значения $x_i$  и добавлять к ним шум по указанной ниже формуле:\n",
    "\n",
    "$\\hat{x}_{i}=x_{i}+\\log \\dfrac{r_{i}}{1-r_{i}}$\n",
    "\n",
    "Этот шум может быть положительным или отрицательным, а $r_i$ принимает значение от $0$ до $1$ из семплируется из равномерного распределения. Затем производится реранжирование согласно предсказаниям с шумом, за счет чего мы добиваемся некоторого перемешивания.\n",
    "\n",
    "Далее мы идём сверху вниз, рассматриваем каждые два подряд идущих документа и увеличиваем суммарный вес этой пары на величину метрики MRR, которая считается согласно указанной ниже формуле:\n",
    "\n",
    "$N_{ij} = \\dfrac{1}{n} \\sum_{t=1}^{n} \\dfrac{1}{{index}_{t}(\\min (i, j))}$\n",
    "\n",
    "Об этой метрике мы говорили на второй лекции. Напомним, что по сути это просто величина, обратная рангу. В паре мы берём самый верхний документ, поэтому нам нужен минимальный индекс, что и записано в знаменателе. После переупорядочивания выборки с шумом в предсказаниях мы берём первый и второй документы и вес этой пары увеличиваем на единицу, так как среднеобратный ранг будет $1$. Потом мы берём второй и третий документы и получаем вес пары $1/2$. Выходит, что у нас есть только веса для тех пар, которые попадались при перемешивании последовательно. Веса остальных пар равны нулю.\n",
    "\n",
    "Процедура внесения шума, перемешивания и расчёта веса повторяется 100 раз, каждый раз у нас получается другая перестановка. Чем выше каждый раз попадает документ, тем больше его вес, и наоборот. Если у нас за эти 100 попыток ни разу не шли подряд какие-либо два документа, а в разметке в датасете у нас для них есть оценка релевантности, то эта пара не будет использоваться при обучении на данной итерации, так как её вес нулевой. Понятно, что в самом начале обучения вес $N_{ij}$ практически ни на что не влияет, и он вообще случайный. Однако он начинает играть существенную роль, когда в бустинге уже есть несколько построенных деревьев, и наши предсказания обретают смысл, а получаемое ранжирование неслучайно.\n",
    "\n",
    "Другая составляющая весов в функции потерь — это вот такая хитрая формула:\n",
    "\n",
    "$c \\left( l_{i}, l_{j} \\right) = \\sum_{u, v} 1_{ u \\gt v} p \\left( u | l_{i} \\right) p \\left( v | l_{j} \\right)$\n",
    "\n",
    "Она помогает нам уделять больше внимания тем парам объектов, у которых нет неопределённости в проставленной оценке релевантности, то есть во входных данных. Здесь $u$ и $v$ — это конкретные оценки для $i$-го и $j$-го документов, например от $1$ до $5$, где $1$ означает нерелевантный мусор, а $5$ — идеальное соответствие.\n",
    "\n",
    "Далее мы пробегаемся по всем возможным комбинациям этих оценок и берём только такие, где релевантность первого документа выше, чем второго, так как у нас в датасете изначально сделан тот же трюк, что использовался в LambdaRANK с перестановкой пар. Для этих комбинаций происходит умножение единицы на две вероятности, характеризующие возможность того, что оценка релевантности в датасете на самом деле выставлена неправильно (люди, размечающие данные, не идеальны и могут ошибаться). Стоит также отметить, что этот множитель у веса пары, а именно функция $c$ от лейблов $l_i$ и $l_j$ не зависит от текущей модели и может быть предрассчитана, так как мы используем только метки из датасета, но не предсказания.\n",
    "\n",
    "Последнее, что хочется обсудить сегодня — как определять “истинные” значения меток в разметке, которые были упомянуты выше, а также как строить такую матрицу на основе своих данных. На самом деле метки не являются истинными, это просто наше предположение о том, какими они должны быть. Для того чтобы выдвинуть такое предположение, все документы в уже векторизованном виде разобъём по так называемым “бакетам”, то есть просто на несколько кластеров. Объединяем объекты в один кластер, если расстояние от текущего $i$-го объекта не больше, чем некоторый маленький $\\epsilon$ до всех других объектов кластера. В идеальном случае у нас в один \"бакет\" должны попадать объекты с одинаковым набором признаков, то есть идентичные документы, но если говорить в целом, то они просто должны быть максимально похожи.\n",
    "\n",
    "Для документов из \"бакета\" мы можем посмотреть на распределение меток релевантности в разметке, и определить превалирующую составляющую. В статье предлагается просто случайно брать метку из этого кластера, взвешивая вероятность взятия на количество объектов с этой меткой в \"бакете\". Если все объекты в кластере максимально похожих объектов имеют одинаковую метку, то это значит, что никакой неопределённости в этом кластере нет. А вот если из 20 объектов 17 имеют отметку “хорошее соответствие”, а 3 — “идеальное” (и это при том, что с точки зрения признакового описания эти объекты максимально похожи), то скорее всего тут возникла какая-то путаница в разметке. А для построения самой confusion матрицы нам подойдёт какой-нибудь итеративный метод, оптимизирующий функцию правдоподобия, то есть можно просто пытаться сделать значения в матрице максимально похожими на ту картину, что мы наблюдаем в \"бакетах\".\n",
    "\n",
    "# **>** **Резюме**\n",
    "\n",
    "- На примере мы разобрались, почему не всегда нужно оптимизировать количество неупорядоченных пар и чем это может обернуться.\n",
    "- Далее мы решили эту проблему с помощью подмены градиентов, реализованной в методе LambdaRank. Новые градиенты зависят напрямую от изменения целевой метрики, а не от функции потерь. Приём подмены градиентов, как оказалось, можно и нужно использовать в деревянных моделях, а именно в градиентном бустинге. На очередной итерации обучения нового дерева нам нужно в качестве целевых значений указать  $\\lambda$, и тогда модель покажет хорошее качество в задаче ранжирования, вобрав в себя плюсы разобранных выше подходов. Однако и этот подход не лишён минусов, и для их разрешения мы вводим в функцию потерь веса, зависящие от важности объекта и от качества нашей разметки.\n",
    "- Всё это предлагает нам такой метод, как YetiRank."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на работу коэффициентов $\\lambda_{ij}$ на практике. Сгенерируем очень плохие предсказания релевантности и попробуем их скорректировать с помощью коэффициентов.\n",
    "\n",
    "$$\n",
    "    \\lambda = \\left(\\frac{1}{2} * (1 - S_{ij}) - \\frac {1} {1 + e^{s_i - s_j}}\\right) |\\Delta_{nDCG}|\n",
    "$$\n",
    "$$\n",
    "    \\Delta_{nDCG} = \\frac {1} {IdealDCG} (2^i - 2^j) \\left(\\frac {1} {log_2(1+i)} - \\frac {1} {log_2(1+j)}\\right),\n",
    "$$\n",
    "$$\n",
    "    N = \\frac{1}{IdealDCG}\n",
    "    \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.FloatTensor([5, 3, 2, 5, 1, 1]).reshape(-1, 1)\n",
    "# Специально предсказываем вторую \"5\" и последнюю \"1\" очень плохо.\n",
    "y_pred = torch.FloatTensor([3.0, -0.5, -0.1, -2.7, 0.001, 2]).reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_labels_in_batch(y_true):\n",
    "    \"\"\"Compute labels value in batch of data: \n",
    "        S_ij = 1 if rel_i > rel_j else -1 (rel_i < rel_j).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : `FloatTensor`\n",
    "        True relevance labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sij : `FloatTensor`\n",
    "        Matrix of label's relevances pairs relation.\n",
    "    \"\"\"\n",
    "    # Relevances difference everyone with everyone\n",
    "    rel_diff = y_true - y_true.T\n",
    "    # 1 here - more relevante\n",
    "    pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "    # 1 here - less relevante\n",
    "    neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "    Sij = pos_pairs - neg_pairs\n",
    "    return Sij\n",
    "\n",
    "\n",
    "def compute_gain_diff(y_true, gain_scheme):\n",
    "    \"\"\"Computes the gain difference between each i and j pairs of y_true.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : `FloatTensor`\n",
    "        True relevance labels.\n",
    "    gain_scheme : `str`\n",
    "        Gain scheme. Allowed values = ['const', 'exp2']\n",
    "            * const : gain = rank;\n",
    "            * exp2  : gain = 2^rank - 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gain_diff : `FloatTensor`\n",
    "        Matrix of gain difference between each i and j pairs of y_true.\n",
    "    \"\"\"\n",
    "    if gain_scheme == \"exp2\":\n",
    "        gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.T)\n",
    "    elif gain_scheme == \"const\":\n",
    "        gain_diff = y_true - y_true.T\n",
    "    else:\n",
    "        raise ValueError(f\"{gain_scheme} method not supported\")\n",
    "    return gain_diff\n",
    "\n",
    "\n",
    "def compute_lambdas(y_true: FloatTensor, \n",
    "                    y_pred: FloatTensor, \n",
    "                    gain_scheme: str = 'exp2') -> FloatTensor:\n",
    "    \"\"\"Computes the lambdas for the true and predicted relevance values\n",
    "    by formula:\n",
    "        ( 1/2 * (1 - S_{ij}) - 1/(1 + exp^(s_i - s_j)) *\n",
    "        | 1/IdealDCG * (2^i - 2^j) * (1/log2(1+i) - 1/log2(1+j)) |\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : `FloatTensor`\n",
    "        True relevance labels.\n",
    "    y_pred : `FloatTensor`\n",
    "        Predicted relevance values.\n",
    "    gain_scheme : `str`\n",
    "        Default='exp2'\n",
    "        Gain scheme. Allowed values = ['const', 'exp2']\n",
    "            * const : gain = rank;\n",
    "            * exp2  : gain = 2^rank - 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lambdas_update : `FloatTensor`\n",
    "        Lambdas values to update y_pred.\n",
    "    \"\"\"\n",
    "    # Norm coeff\n",
    "    ideal_dcg = dcg(y_true, y_true, gain_scheme=gain_scheme)\n",
    "    N = 1 / ideal_dcg\n",
    "    # Sort documents by relevances\n",
    "    _, rank_order = torch.sort(y_true, descending=True, dim=0)\n",
    "    # i,j \\in \\N from 1\n",
    "    rank_order += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Compute 1 + exp^(s_i - s_j) for y_pred\n",
    "        pairs_scores_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "        # Compute S_ij = 1 if rel_i > rel_j else -1\n",
    "        Sij = compute_labels_in_batch(y_true)\n",
    "        # Compute gain difference (i - j) or (2^i - 2^j)\n",
    "        gain_diff = compute_gain_diff(y_true, gain_scheme)\n",
    "        # Compute position change in denominators (1/log2(1+i) - 1/log2(1+j) \n",
    "        denominators_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "        # Delta nDCG\n",
    "        delta_ndcg = torch.abs(N * gain_diff * denominators_diff)\n",
    "        # Compute lambdas\n",
    "        lambda_update = (0.5 * (1 - Sij) - 1 / pairs_scores_diff) * delta_ndcg\n",
    "        # Sum lambdas over j axis\n",
    "        lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "    return lambda_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1232],\n",
       "        [ 0.0150],\n",
       "        [ 0.0640],\n",
       "        [-0.2205],\n",
       "        [ 0.0798],\n",
       "        [ 0.1849]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_lambdas(y_true, y_pred, 'exp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "steps = 100\n",
    "\n",
    "for _ in range(steps):\n",
    "    lambda_update = compute_lambdas(y_true, y_pred, gain_scheme='exp2')\n",
    "    y_pred -= lambda_update\n",
    "    scores.append(ndcg(y_true, y_pred))\n",
    "\n",
    "\n",
    "plt.plot(range(steps), scores)\n",
    "plt.grid()\n",
    "plt.xlabel('#_steps of $\\lambda$ update')\n",
    "plt.ylabel('$nDCG$')\n",
    "plt.title(\"$nDCG$ evaluation per #_steps of $\\lambda$ updates\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем _градиентный бустинг_ на основе вычисления $\\lambda$, используя сокращённый датасет [msrank_10k](https://catboost.ai/en/docs/concepts/python-reference_datasets_msrank_10k)\n",
    "\n",
    "В качестве базового алгоритма для бустинга будем использовать `DecisionTreeRegressor` из библиотеки `sklearn`. Целевыми метками, на которые обучается каждое дерево, вместо типичных для бустинга ошибок (невязок), будут $\\lambda$-значения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры класса\n",
    "\n",
    "* `n_estimators` — количество деревьев, которые будут строиться в рамках бустинга;\n",
    "* `lr` — _Learning Rate_, коэффициент, на который умножаются предсказания каждого нового дерева в алгоритме (каждое дерево учится предсказывать значение $\\lambda$, но не факт, что добавление к текущим предсказаниям такого значения даст оптимум, поэтому весь “путь” оптимизации разбивается на маленькие шаги);\n",
    "* `subsample` — доля объектов от выборки, на которых обучается каждое дерево (доля одинакова для всех деревьев, но сама подвыборка генерируется на каждом шаге отдельно).\n",
    "* `colsample_bytree` — доля признаков от выборки, на которых обучается каждое дерево (доля одинакова для всех деревьев, но сама подвыборка генерируется на каждом шаге отдельно).\n",
    "\n",
    "Совокупность двух вышеуказанных параметров позволяет реализовать [метод случайных подпространств](https://en.wikipedia.org/wiki/Random_subspace_method#Algorithm). Понятно, что для применения деревьев (получения предсказания) нужно хранить индексы использованных признаков (но не объектов).\n",
    "\n",
    "* `max_depth` и `min_samples_leaf` — параметры `DecisionTreeRegressor`, отвечающие за глубину построения дерева и минимальное количество в терминальных (финальных) листьях дерева соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDTLambdaRank:\n",
    "    def __init__(self,\n",
    "                 n_estimators: int,\n",
    "                 lr: float,\n",
    "                 subsample: float,\n",
    "                 colsample_bytree: float,\n",
    "                 max_depth: int,\n",
    "                 min_samples_leaf: int,\n",
    "                 metric_func: Callable[[torch.FloatTensor, torch.FloatTensor], float],\n",
    "                 metric_params: Dict[str, Any]=None):\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "        self.metric_func = metric_func\n",
    "        if 'metric_name' in metric_params:\n",
    "            self.metric_name = deepcopy(metric_params['metric_name'])\n",
    "            del metric_params['metric_name']\n",
    "        else:\n",
    "            self.metric_name = self.metric_func.__name__\n",
    "        if 'top_k' in metric_params:\n",
    "            self.top_k = metric_params['top_k']\n",
    "        \n",
    "        self.metric_params = metric_params\n",
    "        # Trees parameters\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        # Model parameters\n",
    "        self.trees = []\n",
    "        self.tree_features = []\n",
    "        self.best_metric_value = 0\n",
    "        self.prune_ind = -1\n",
    "        # Data parameters\n",
    "        self.n_samples = round(self.subsample * self.X_train.shape[0])\n",
    "        self.n_features = round(self.colsample_bytree * self.X_train.shape[1])\n",
    "\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        # [0, 1] column index = target/queryGroupID columns\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, \n",
    "                X_test, y_test, query_ids_test]\n",
    "\n",
    "\n",
    "    def _scale_features_by_query_groups(self, \n",
    "                                        features: np.ndarray, \n",
    "                                        query_ids: np.ndarray) -> np.ndarray:\n",
    "        for query_id in np.unique(query_ids):\n",
    "            mask = query_id == query_ids\n",
    "            scaler = StandardScaler()\n",
    "            features[mask] = scaler.fit_transform(features[mask])\n",
    "        return features\n",
    "\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        self.query_ids_train_unique = np.unique(self.query_ids_train)\n",
    "        self.query_ids_test_unique = np.unique(self.query_ids_test)\n",
    "\n",
    "        X_train = self._scale_features_by_query_groups(X_train, self.query_ids_train)\n",
    "        X_test = self._scale_features_by_query_groups(X_test, self.query_ids_train)\n",
    "        \n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "        self.y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "        self.y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "\n",
    "    def _compute_labels_in_batch(self, y_true: FloatTensor) -> FloatTensor:\n",
    "        \"\"\"Compute labels value in batch of data: \n",
    "            S_ij = 1 if rel_i > rel_j else -1 (rel_i < rel_j).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : `FloatTensor`\n",
    "            True relevance labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Sij : `FloatTensor`\n",
    "            Matrix of label's relevances pairs relation.\n",
    "        \"\"\"\n",
    "        # Relevances difference everyone with everyone\n",
    "        rel_diff = y_true - y_true.T\n",
    "        # 1 here - more relevante\n",
    "        pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "        # 1 here - less relevante\n",
    "        neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "        Sij = pos_pairs - neg_pairs\n",
    "        return Sij\n",
    "\n",
    "\n",
    "    def _compute_gain_diff(self, y_true: FloatTensor, \n",
    "                           gain_scheme: str) -> FloatTensor:\n",
    "        \"\"\"Computes the gain difference between each i and j pairs of y_true.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        y_true : `FloatTensor`\n",
    "            True relevance labels.\n",
    "        gain_scheme : `str`\n",
    "            Gain scheme. Allowed values = ['const', 'exp2']\n",
    "                * const : gain = rank;\n",
    "                * exp2  : gain = 2^rank - 1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gain_diff : `FloatTensor`\n",
    "            Matrix of gain difference between each i and j pairs of y_true.\n",
    "        \"\"\"\n",
    "        if gain_scheme == \"exp2\":\n",
    "            gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.T)\n",
    "        elif gain_scheme == \"const\":\n",
    "            gain_diff = y_true - y_true.T\n",
    "        else:\n",
    "            raise ValueError(f\"{gain_scheme} method not supported\")\n",
    "        return gain_diff\n",
    "\n",
    "\n",
    "    def _compute_lambdas(self, y_true: FloatTensor, \n",
    "                         y_pred: FloatTensor, \n",
    "                         gain_scheme: str = 'exp2') -> FloatTensor:\n",
    "        \"\"\"Computes the lambdas for the true and predicted relevance values\n",
    "        by formula:\n",
    "            ( 1/2 * (1 - S_{ij}) - 1/(1 + exp^(s_i - s_j)) *\n",
    "            | 1/IdealDCG * (2^i - 2^j) * (1/log2(1+i) - 1/log2(1+j)) |\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : `FloatTensor`\n",
    "            True relevance labels.\n",
    "        y_pred : `FloatTensor`\n",
    "            Predicted relevance values.\n",
    "        gain_scheme : `str`\n",
    "            Default='exp2'\n",
    "            Gain scheme. Allowed values = ['const', 'exp2']\n",
    "                * const : gain = rank;\n",
    "                * exp2  : gain = 2^rank - 1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lambdas_update : `FloatTensor`\n",
    "            Lambdas values to update y_pred.\n",
    "        \"\"\"\n",
    "        # Norm coeff\n",
    "        if hasattr(self, 'top_k'):\n",
    "            ideal_dcg = dcg(y_true, y_true, gain_scheme=gain_scheme, top_k=self.top_k)\n",
    "        else:\n",
    "            ideal_dcg = dcg(y_true, y_true, gain_scheme=gain_scheme)\n",
    "        N = 1 / ideal_dcg if ideal_dcg != 0 else 0\n",
    "        # Sort documents by relevances\n",
    "        _, rank_order = torch.sort(y_true, descending=True, dim=0)\n",
    "        # i,j \\in \\N from 1\n",
    "        rank_order += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Compute 1 + exp^(s_i - s_j) for y_pred\n",
    "            pairs_scores_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "            # Compute S_ij = 1 if rel_i > rel_j else -1\n",
    "            Sij = self._compute_labels_in_batch(y_true)\n",
    "            # Compute gain difference (i - j) or (2^i - 2^j)\n",
    "            gain_diff = self._compute_gain_diff(y_true, gain_scheme)\n",
    "            # Compute position change in denominators (1/log2(1+i) - 1/log2(1+j) \n",
    "            denominators_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "            # Delta nDCG\n",
    "            delta_ndcg = torch.abs(N * gain_diff * denominators_diff)\n",
    "            # Compute lambdas\n",
    "            lambda_update = (0.5 * (1 - Sij) - 1 / pairs_scores_diff) * delta_ndcg\n",
    "            # Sum lambdas over j axis\n",
    "            lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "        return lambda_update\n",
    "\n",
    "\n",
    "    def _train_one_tree(self, cur_tree_idx: int, \n",
    "                        train_preds: FloatTensor) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        np.random.seed(cur_tree_idx)\n",
    "        samples = np.random.choice(np.arange(self.X_train.shape[0]).tolist(), self.n_samples, replace=False)\n",
    "        features = np.random.choice(np.arange(self.X_train.shape[1]).tolist(), self.n_features, replace=False)\n",
    "        # Compute lambdas separately for each query\n",
    "        lambdas = torch.zeros(list(self.y_train.shape)[0]).unsqueeze(1)\n",
    "        for query_id in self.query_ids_train_unique:\n",
    "            mask = self.query_ids_train == query_id\n",
    "            lambdas[mask] = self._compute_lambdas(self.y_train[mask], train_preds[mask])\n",
    "        lambdas = lambdas[samples]\n",
    "        # Random subspace method\n",
    "        X_train = self.X_train[samples][:, features]\n",
    "        tree = DecisionTreeRegressor(max_depth=self.max_depth,\n",
    "                                     min_samples_leaf=self.min_samples_leaf,\n",
    "                                     random_state=cur_tree_idx)\n",
    "        tree.fit(X_train, -lambdas)\n",
    "\n",
    "        return tree, features\n",
    "\n",
    "    def _calculate_loss(self, query_ids: np.ndarray,\n",
    "                        y_true: FloatTensor,\n",
    "                        y_pred: FloatTensor) -> float:\n",
    "        loss = []\n",
    "        for query_id in np.unique(query_ids):\n",
    "            mask = query_ids == query_id\n",
    "            batch_y_true = y_true[mask].flatten()\n",
    "            batch_y_pred = y_pred[mask].flatten()\n",
    "            metric_value = self.metric_func(batch_y_true, batch_y_pred, **self.metric_params)\n",
    "            loss.append(metric_value)\n",
    "        return np.mean(loss)\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        print(\"Fit:\")\n",
    "        y_train_pred, y_test_pred = 0 * self.y_train, 0 * self.y_test\n",
    "        for k in range(self.n_estimators):\n",
    "            # Train k-th tree\n",
    "            tree, features = self._train_one_tree(k, y_train_pred)\n",
    "            y_train_pred += self.lr * FloatTensor(tree.predict(self.X_train[:, features])).unsqueeze(1)\n",
    "            y_test_pred += self.lr * FloatTensor(tree.predict(self.X_test[:, features])).unsqueeze(1)\n",
    "            # Metric value\n",
    "            metric_value = self._calculate_loss(self.query_ids_test, self.y_test, y_test_pred)\n",
    "            if metric_value > self.best_metric_value:\n",
    "                self.best_metric_value, self.prune_ind = metric_value, k + 1\n",
    "            # Save k-th tree\n",
    "            self.trees.append(tree)\n",
    "            self.tree_features.append(features)\n",
    "            print(f\"\\t{self.metric_name}:{metric_value:.4f}\",\n",
    "                  f\"\\tbest:{self.best_metric_value:.4f}\")\n",
    "        print(f\"{self.metric_name}:{self.best_metric_value:.4f}\")\n",
    "        self.trees = self.trees[:self.prune_ind]\n",
    "        self.tree_features = self.tree_features[:self.prune_ind]\n",
    "\n",
    "\n",
    "    def predict(self, data: FloatTensor) -> FloatTensor:\n",
    "        y_pred = FloatTensor(torch.zeros(list(data.shape)[0])).unsqueeze(1)\n",
    "        for k in range(self.prune_ind):\n",
    "            y_pred += self.lr * FloatTensor(self.trees[k].predict(data[:, self.tree_features[k]])).unsqueeze(1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def save_model(self, \n",
    "                   path=f\"./models/GBDTLambdaRank__{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\"\n",
    "    ) -> None:\n",
    "        if not os.path.exists('models'):\n",
    "            os.makedirs('models')\n",
    "        model = {\n",
    "            \"tree_features\": self.tree_features,\n",
    "            \"trees\": self.trees,\n",
    "            \"lr\": self.lr,\n",
    "            \"prune_ind\": self.prune_ind\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "\n",
    "    def load_model(self, path='./models/GBDTLambdaRank__best.pth') -> None:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        self.tree_features = model['tree_features']\n",
    "        self.trees = model['trees']\n",
    "        self.lr = model['lr']\n",
    "        self.prune_ind = model['prune_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, model, path_to_model, params, param_space, model_params, max_evals=-1):\n",
    "        self.model = model\n",
    "        self.path_to_model = path_to_model\n",
    "        self.param_space = param_space\n",
    "        self.params = params\n",
    "        self.model_params = model_params\n",
    "        self.max_evals = max_evals\n",
    "\n",
    "    def train(self):\n",
    "        if self.max_evals > 0:\n",
    "            params = self._find_best_params()\n",
    "            # add start points\n",
    "            params[\"max_depth\"] += 3\n",
    "            params[\"min_samples_leaf\"] += 5\n",
    "        else:\n",
    "            params = self.params\n",
    "            \n",
    "        params_file = os.path.join(os.path.dirname(self.path_to_model), 'best_params.json')\n",
    "        with open(params_file, 'w') as json_file:\n",
    "            json.dump(params, json_file, indent=4)\n",
    "        print(params)\n",
    "        model = self.model(**params, **self.model_params)\n",
    "        model.fit()\n",
    "        model.save_model(self.path_to_model)\n",
    "\n",
    "\n",
    "    def objective(self, params):\n",
    "        estimator = self.model(**params)\n",
    "        estimator.fit()\n",
    "\n",
    "        return -estimator.best_metric_value\n",
    "\n",
    "\n",
    "    def _find_best_params(self) -> dict:\n",
    "        best_params = hopt.fmin(fn=self.objective, \n",
    "                                space=self.param_space, \n",
    "                                algo=hopt.tpe.suggest, \n",
    "                                max_evals=self.max_evals, \n",
    "                                show_progressbar=True)\n",
    "        return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_SPACE = {\n",
    "    'max_depth': 1 + hp.randint('max_depth', 50),\n",
    "    'lr': hp.uniform('lr', 0.0001, 0.9),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.01, 0.9),\n",
    "    'subsample': hp.uniform('subsample', 0.001, 0.9),\n",
    "    'min_samples_leaf': 1 + hp.randint('min_samples_leaf', 500),\n",
    "}\n",
    "MODEL_PARAMS = {\n",
    "    'metric_func': ndcg_k,\n",
    "    'metric_params': {'top_k': 10, 'gain_scheme': 'exp2', 'metric_name': 'nDCG@10'}\n",
    "}\n",
    "PARAMS_BEST = {\n",
    "    'n_estimators': 100,\n",
    "    'colsample_bytree': 0.803405898238231, \n",
    "    'lr': 0.38838647219386685, \n",
    "    'max_depth': 13, \n",
    "    'min_samples_leaf': 42, \n",
    "    'subsample': 0.7609862969339997\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      ">>> Start @Training\n",
      "{'n_estimators': 100, 'colsample_bytree': 0.803405898238231, 'lr': 0.38838647219386685, 'max_depth': 13, 'min_samples_leaf': 42, 'subsample': 0.7609862969339997}\n",
      "Fit:\n",
      "\tnDCG@10:0.2939 \tbest:0.2939\n",
      "\tnDCG@10:0.3254 \tbest:0.3254\n",
      "\tnDCG@10:0.3410 \tbest:0.3410\n",
      "\tnDCG@10:0.3522 \tbest:0.3522\n",
      "\tnDCG@10:0.3695 \tbest:0.3695\n",
      "\tnDCG@10:0.3658 \tbest:0.3695\n",
      "\tnDCG@10:0.3677 \tbest:0.3695\n",
      "\tnDCG@10:0.3743 \tbest:0.3743\n",
      "\tnDCG@10:0.3740 \tbest:0.3743\n",
      "\tnDCG@10:0.3834 \tbest:0.3834\n",
      "\tnDCG@10:0.3872 \tbest:0.3872\n",
      "\tnDCG@10:0.3886 \tbest:0.3886\n",
      "\tnDCG@10:0.3878 \tbest:0.3886\n",
      "\tnDCG@10:0.4014 \tbest:0.4014\n",
      "\tnDCG@10:0.4001 \tbest:0.4014\n",
      "\tnDCG@10:0.3991 \tbest:0.4014\n",
      "\tnDCG@10:0.4083 \tbest:0.4083\n",
      "\tnDCG@10:0.4075 \tbest:0.4083\n",
      "\tnDCG@10:0.4066 \tbest:0.4083\n",
      "\tnDCG@10:0.4062 \tbest:0.4083\n",
      "\tnDCG@10:0.4029 \tbest:0.4083\n",
      "\tnDCG@10:0.4070 \tbest:0.4083\n",
      "\tnDCG@10:0.4072 \tbest:0.4083\n",
      "\tnDCG@10:0.4124 \tbest:0.4124\n",
      "\tnDCG@10:0.4120 \tbest:0.4124\n",
      "\tnDCG@10:0.4128 \tbest:0.4128\n",
      "\tnDCG@10:0.4112 \tbest:0.4128\n",
      "\tnDCG@10:0.4136 \tbest:0.4136\n",
      "\tnDCG@10:0.4164 \tbest:0.4164\n",
      "\tnDCG@10:0.4154 \tbest:0.4164\n",
      "\tnDCG@10:0.4123 \tbest:0.4164\n",
      "\tnDCG@10:0.4145 \tbest:0.4164\n",
      "\tnDCG@10:0.4161 \tbest:0.4164\n",
      "\tnDCG@10:0.4137 \tbest:0.4164\n",
      "\tnDCG@10:0.4181 \tbest:0.4181\n",
      "\tnDCG@10:0.4168 \tbest:0.4181\n",
      "\tnDCG@10:0.4165 \tbest:0.4181\n",
      "\tnDCG@10:0.4179 \tbest:0.4181\n",
      "\tnDCG@10:0.4208 \tbest:0.4208\n",
      "\tnDCG@10:0.4211 \tbest:0.4211\n",
      "\tnDCG@10:0.4215 \tbest:0.4215\n",
      "\tnDCG@10:0.4249 \tbest:0.4249\n",
      "\tnDCG@10:0.4200 \tbest:0.4249\n",
      "\tnDCG@10:0.4211 \tbest:0.4249\n",
      "\tnDCG@10:0.4185 \tbest:0.4249\n",
      "\tnDCG@10:0.4189 \tbest:0.4249\n",
      "\tnDCG@10:0.4232 \tbest:0.4249\n",
      "\tnDCG@10:0.4204 \tbest:0.4249\n",
      "\tnDCG@10:0.4240 \tbest:0.4249\n",
      "\tnDCG@10:0.4222 \tbest:0.4249\n",
      "\tnDCG@10:0.4195 \tbest:0.4249\n",
      "\tnDCG@10:0.4218 \tbest:0.4249\n",
      "\tnDCG@10:0.4207 \tbest:0.4249\n",
      "\tnDCG@10:0.4243 \tbest:0.4249\n",
      "\tnDCG@10:0.4250 \tbest:0.4250\n",
      "\tnDCG@10:0.4230 \tbest:0.4250\n",
      "\tnDCG@10:0.4236 \tbest:0.4250\n",
      "\tnDCG@10:0.4220 \tbest:0.4250\n",
      "\tnDCG@10:0.4228 \tbest:0.4250\n",
      "\tnDCG@10:0.4207 \tbest:0.4250\n",
      "\tnDCG@10:0.4215 \tbest:0.4250\n",
      "\tnDCG@10:0.4241 \tbest:0.4250\n",
      "\tnDCG@10:0.4213 \tbest:0.4250\n",
      "\tnDCG@10:0.4241 \tbest:0.4250\n",
      "\tnDCG@10:0.4244 \tbest:0.4250\n",
      "\tnDCG@10:0.4236 \tbest:0.4250\n",
      "\tnDCG@10:0.4215 \tbest:0.4250\n",
      "\tnDCG@10:0.4255 \tbest:0.4255\n",
      "\tnDCG@10:0.4251 \tbest:0.4255\n",
      "\tnDCG@10:0.4223 \tbest:0.4255\n",
      "\tnDCG@10:0.4215 \tbest:0.4255\n",
      "\tnDCG@10:0.4213 \tbest:0.4255\n",
      "\tnDCG@10:0.4227 \tbest:0.4255\n",
      "\tnDCG@10:0.4246 \tbest:0.4255\n",
      "\tnDCG@10:0.4262 \tbest:0.4262\n",
      "\tnDCG@10:0.4241 \tbest:0.4262\n",
      "\tnDCG@10:0.4273 \tbest:0.4273\n",
      "\tnDCG@10:0.4282 \tbest:0.4282\n",
      "\tnDCG@10:0.4259 \tbest:0.4282\n",
      "\tnDCG@10:0.4278 \tbest:0.4282\n",
      "\tnDCG@10:0.4274 \tbest:0.4282\n",
      "\tnDCG@10:0.4268 \tbest:0.4282\n",
      "\tnDCG@10:0.4298 \tbest:0.4298\n",
      "\tnDCG@10:0.4305 \tbest:0.4305\n",
      "\tnDCG@10:0.4310 \tbest:0.4310\n",
      "\tnDCG@10:0.4319 \tbest:0.4319\n",
      "\tnDCG@10:0.4293 \tbest:0.4319\n",
      "\tnDCG@10:0.4261 \tbest:0.4319\n",
      "\tnDCG@10:0.4245 \tbest:0.4319\n",
      "\tnDCG@10:0.4261 \tbest:0.4319\n",
      "\tnDCG@10:0.4261 \tbest:0.4319\n",
      "\tnDCG@10:0.4270 \tbest:0.4319\n",
      "\tnDCG@10:0.4282 \tbest:0.4319\n",
      "\tnDCG@10:0.4291 \tbest:0.4319\n",
      "\tnDCG@10:0.4293 \tbest:0.4319\n",
      "\tnDCG@10:0.4331 \tbest:0.4331\n",
      "\tnDCG@10:0.4303 \tbest:0.4331\n",
      "\tnDCG@10:0.4308 \tbest:0.4331\n",
      "\tnDCG@10:0.4285 \tbest:0.4331\n",
      "\tnDCG@10:0.4278 \tbest:0.4331\n",
      "nDCG@10:0.4331\n",
      ">>> End @Training\n"
     ]
    }
   ],
   "source": [
    "print('---'*25)\n",
    "print('>>> Start @Training')\n",
    "trainer = TrainModel(\n",
    "    model=GBDTLambdaRank,\n",
    "    path_to_model='./models/GBDTLambdaRank.bin',\n",
    "    params=PARAMS_BEST,\n",
    "    param_space=PARAMS_SPACE,\n",
    "    model_params=MODEL_PARAMS,\n",
    "    max_evals=-1\n",
    ")\n",
    "trainer.train()\n",
    "print('>>> End @Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      ">>> Start @Inference\n",
      ">>> Eval ndcg_k@10 = 0.4331\n",
      ">>> End @Prediction with 96 trees\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---'*25)\n",
    "print('>>> Start @Inference')\n",
    "\n",
    "with open('./models/best_params.json', 'r') as params_json:\n",
    "    best_params = json.loads(params_json.read())\n",
    "params = {**MODEL_PARAMS, **best_params}\n",
    "\n",
    "estimator = GBDTLambdaRank(**params)\n",
    "estimator.load_model('./models/GBDTLambdaRank.bin')\n",
    "\n",
    "y_pred = estimator.predict(estimator.X_test)\n",
    "\n",
    "metric_value = estimator._calculate_loss(estimator.query_ids_test, estimator.y_test, y_pred)\n",
    "print(f\">>> Eval {params['metric_func'].__name__}@{params['metric_params']['top_k']} = {metric_value:.4f}\")\n",
    "print(f\">>> End @Prediction with {len(estimator.trees)} trees\")\n",
    "print('---'*25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
