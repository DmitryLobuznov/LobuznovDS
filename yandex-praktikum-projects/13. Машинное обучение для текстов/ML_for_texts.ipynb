{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–µ–∫—Ç –¥–ª—è ¬´–í–∏–∫–∏—à–æ–ø¬ª\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é.\n",
    "–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –í –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.\n",
    " * –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ F1 –Ω–µ –º–µ–Ω—å—à–µ 0.75.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–∏–∑–Ω–∞–∫–∏:**  \n",
    "* `text` ‚Äî —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è;\n",
    "* `toxic` ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "<a href='#section1'></a>\n",
    "1. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö](#section1)  \n",
    "    1.1 [–ü–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä](#section1.1)  \n",
    "    1.2. [–û—á–∏—Å—Ç–∫–∞ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤](#section1.2)   \n",
    "<a href='#section2'></a>  \n",
    "2. [–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏](#section2)  \n",
    "    2.1. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫ –æ–±—É—á–µ–Ω–∏—é](#section2.1)  \n",
    "    2.2. [LogisticRegression](#section2.2)  \n",
    "    2.3. [DecisionTreeClassifier](#section2.3)    \n",
    "    2.4. [LGBMClassifier](#section2.4)  \n",
    "    2.5. [LinearSVC](#section2.5)  \n",
    "    2.6. [–í—ã–≤–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è](#section2.6)  \n",
    "    2.7. [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ](#section2.7)  \n",
    "<a href='#section3'></a>  \n",
    "3. [–í—ã–≤–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è](#section3)\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# String\n",
    "import re\n",
    "import string\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# –ú–æ–¥–µ–ª–∏\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "from time import time\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score,  f1_score,  roc_auc_score, roc_curve, make_scorer\n",
    "# –ì—Ä–∞—Ñ–∏–∫–∞\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(\"paper\")\n",
    "# nltk\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "punctuation = string.punctuation \n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1.1'></a>\n",
    "### 1.1 –ü–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∫–ª–∞—Å—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.83"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['toxic'].value_counts())\n",
    "\n",
    "class_ratio = round(data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1], 2)\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–º–µ–µ–º —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: `1 : 8.83`.  \n",
    "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –≤–µ—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ —ç—Ç–∏–º –∏ —Ä–∞–∑–æ–±—å—ë–º –Ω–∞ –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1.2'></a>\n",
    "### 1.2 –û—á–∏—Å—Ç–∫–∞ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å `Mystem` –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `pymystem3`, –æ–¥–Ω–∞–∫–æ –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —É–ª–µ—Ç–µ–ª –∑–∞ –ø–æ–ª—á–∞—Å–∞ => —Ä–µ—à–µ–Ω–æ –±—ã–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `WordNetLemmatizer` –∏ —Ñ—É–Ω–∫—Ü–∏–∏ `map`, `filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_of_text(text):\n",
    "    tokens = [word for w in sent_tokenize(text) for word in word_tokenize(w)]\n",
    "    # Remove punctuation inside words\n",
    "    tokens = list(filter(lambda token: token not in punctuation, tokens)) \n",
    "    # Remove stopwords\n",
    "    tokens = list(filter(lambda token: token.lower() not in stop_words, tokens))\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search(\"[a-zA-Z]\", token):\n",
    "            filtered_tokens.append(token)\n",
    "    # lemmatize text\n",
    "    filtered_tokens = list(map(lambda token: wordnet_lemmatizer.lemmatize(token.lower()), filtered_tokens)) \n",
    "    filtered_tokens = list(filter(lambda token: token not in punctuation, filtered_tokens))\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data[\"clear_text\"] = data[\"text\"].map(preparation_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour 'm seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man 'm really trying edit war 's guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't make real suggestion improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                         clear_text\n",
       "0      0  explanation edits made username hardcore metal...\n",
       "1      0  d'aww match background colour 'm seemingly stu...\n",
       "2      0  hey man 'm really trying edit war 's guy const...\n",
       "3      0  ca n't make real suggestion improvement wonder...\n",
       "4      0                   sir hero chance remember page 's"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(\"text\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_valid_test_split(data : pd.DataFrame, target_column : str, proportions=[0.6, 0.2, 0.2]):\n",
    "#     \"\"\"\n",
    "#     Function splits by train, validation, test parts income dataframe.\n",
    "#     In:\n",
    "#         df : pandas.DataFrame() - income dataframe.\n",
    "#         proportions : list() - list of proportions values to split method.\n",
    "#     \"\"\"\n",
    "#     if sum([*proportions]) != 1:\n",
    "#         raise AttributeError('Wrong \"proportions\" values. Sum of \"proportions\" values > 1.0. Must be equal to 1.0.')\n",
    "#     data_list = [train, valid, test] = np.split(\n",
    "#         data.sample(frac=1, random_state=314), \n",
    "#         [int(proportions[0] * len(data)), int(sum(proportions[:2]) * len(data))]\n",
    "#     )\n",
    "#     features, targets = list(), list()\n",
    "#     for data in data_list:\n",
    "#         features.append(data.drop(target_column, axis=1))\n",
    "#         targets.append(data[target_column])\n",
    "#     return [*features, *targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"toxic\"]\n",
    "features = data.drop(\"toxic\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shapes || (127656, 1) || (31915, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.2, random_state=314)\n",
    "print(\"X_shapes\", X_train.shape, X_test.shape, sep=' || ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>71831</td>\n",
       "      <td>think mucha lucha homosexual show 've ever wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38139</td>\n",
       "      <td>swore well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6079</td>\n",
       "      <td>corrected thee countless ahs china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31624</td>\n",
       "      <td>n't offended 'm sorry keep fixing indentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129677</td>\n",
       "      <td>previous full lupine state allowed lift ton sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clear_text\n",
       "71831   think mucha lucha homosexual show 've ever wit...\n",
       "38139                                          swore well\n",
       "6079                   corrected thee countless ahs china\n",
       "31624   n't offended 'm sorry keep fixing indentation ...\n",
       "129677  previous full lupine state allowed lift ton sa..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω—ã–µ –Ω–∞ –±–∞–∑–µüòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.1'></a>\n",
    "### 2.1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫ –æ–±—É—á–µ–Ω–∏—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = X_train[\"clear_text\"].values.astype('U')\n",
    "test_corpus = X_test[\"clear_text\"].values.astype('U')\n",
    "# Vectorizer\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "# Fit_trasform train & transform others.\n",
    "X_train = count_tf_idf.fit_transform(train_corpus)\n",
    "X_test = count_tf_idf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, X, y, param_grid, scoring):\n",
    "    model_cv = GridSearchCV(\n",
    "        model(),\n",
    "        param_grid = param_grid,\n",
    "        cv = 4,\n",
    "        scoring = scoring,\n",
    "        n_jobs = -1,\n",
    "        verbose = 10,\n",
    "        return_train_score = True\n",
    "    )\n",
    "    # –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    model_cv = model_cv.fit(X, y)\n",
    "    # Best etimator\n",
    "    model_best = model_cv.best_estimator_\n",
    "    cv_results = model_cv.cv_results_\n",
    "\n",
    "    # Train\n",
    "    start_time = time()\n",
    "    model_best.fit(X, y)\n",
    "    train_time = time() - start_time\n",
    "    # Predict\n",
    "    start_time = time()\n",
    "    predictions = model_best.predict(X)\n",
    "    predict_time = time() - start_time\n",
    "    # F1-score metrics\n",
    "    f1_score_metrics = f1_score(y, predictions)\n",
    "    # Result list\n",
    "    rlt = [{\n",
    "        \"Model name\" : type(model_best).__name__,\n",
    "        \"Train time\" : round(train_time, 4),\n",
    "        \"Predict time\" : round(predict_time, 4),\n",
    "        \"F1 train_score\" : model_cv.best_score_.round(4),\n",
    "        \"F1 predict_score\" : round(f1_score_metrics, 4),\n",
    "        \"Parameters\" : model_cv.best_params_\n",
    "    }]\n",
    "    return model_best, model_cv.best_params_, rlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.2'></a>\n",
    "### 2.2 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_params_dict = {\n",
    "    \"random_state\" : [314],\n",
    "    \"penalty\" : [\"l1\"],\n",
    "    \"class_weight\" : [None, \"balanced\"],\n",
    "    \"max_iter\" : range(5, 20, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  64 | elapsed:   33.0s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'LogisticRegression',\n",
       " 'Train time': 0.392,\n",
       " 'Predict time': 0.011,\n",
       " 'F1 train_score': 0.7682,\n",
       " 'F1 predict_score': 0.7955,\n",
       " 'Parameters': {'class_weight': None,\n",
       "  'max_iter': 5,\n",
       "  'penalty': 'l1',\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg, logreg_params, logreg_result = cross_validation(\n",
    "    model = LogisticRegression,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = logreg_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += logreg_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.3'></a>\n",
    "### 2.3 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params_dict = {\n",
    "    \"random_state\" : [314],\n",
    "    \"max_depth\" : range(2, 4),\n",
    "    \"min_samples_split\" : range(2, 4),\n",
    "    \"min_samples_leaf\" : range(2, 4),\n",
    "    \"class_weight\" : [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  64 | elapsed:  1.8min remaining:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'DecisionTreeClassifier',\n",
       " 'Train time': 1.0642,\n",
       " 'Predict time': 0.1127,\n",
       " 'F1 train_score': 0.4265,\n",
       " 'F1 predict_score': 0.4288,\n",
       " 'Parameters': {'class_weight': None,\n",
       "  'max_depth': 3,\n",
       "  'min_samples_leaf': 2,\n",
       "  'min_samples_split': 2,\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree, tree_params, tree_result = cross_validation(\n",
    "    model = DecisionTreeClassifier,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = tree_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += tree_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.4'></a>\n",
    "### 2.4 LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_dict = {\n",
    "    \"random_state\" : [314],\n",
    "    \"learning_rate\" : [0.25, 0.3],\n",
    "    \"n_estimators\" : [150, 200, 250],\n",
    "    \"max_depth\" : range(3, 5),\n",
    "    \"class_weight\" : [\"balanced\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  48 | elapsed:  4.6min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  48 | elapsed:  5.0min remaining:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  5.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'LGBMClassifier',\n",
       " 'Train time': 15.9514,\n",
       " 'Predict time': 0.5525,\n",
       " 'F1 train_score': 0.7427,\n",
       " 'F1 predict_score': 0.783,\n",
       " 'Parameters': {'class_weight': 'balanced',\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 4,\n",
       "  'n_estimators': 200,\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb, lgb_params, lgb_result = cross_validation(\n",
    "    model = LGBMClassifier,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = lgb_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += lgb_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.5'></a>\n",
    "### 2.5 LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params_dict = {\n",
    "    \"C\" : [x / 10 for x in range(1, 21)],\n",
    "    \"max_iter\" : [5, 7, 10, 25, 100],\n",
    "    \"class_weight\" : [\"balanced\"],\n",
    "    \"random_state\" : [314]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'LinearSVC',\n",
       " 'Train time': 0.2563,\n",
       " 'Predict time': 0.013,\n",
       " 'F1 train_score': 0.7746,\n",
       " 'F1 predict_score': 0.8819,\n",
       " 'Parameters': {'C': 0.7,\n",
       "  'class_weight': 'balanced',\n",
       "  'max_iter': 5,\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svc, svc_params_dict, svc_result = cross_validation(\n",
    "    model = LinearSVC,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = svc_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += svc_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_results(results : list):    \n",
    "    return (pd.DataFrame(results)\n",
    "        .style\n",
    "        .highlight_min(color='orange')\n",
    "        .highlight_max(color='lightgreen')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col2 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col3 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col4 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col1 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col2 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col1 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col3 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col4 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model name</th>        <th class=\"col_heading level0 col1\" >Train time</th>        <th class=\"col_heading level0 col2\" >Predict time</th>        <th class=\"col_heading level0 col3\" >F1 train_score</th>        <th class=\"col_heading level0 col4\" >F1 predict_score</th>        <th class=\"col_heading level0 col5\" >Parameters</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col1\" class=\"data row0 col1\" >0.392</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col2\" class=\"data row0 col2\" >0.011</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col3\" class=\"data row0 col3\" >0.7682</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col4\" class=\"data row0 col4\" >0.7955</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col5\" class=\"data row0 col5\" >{'class_weight': None, 'max_iter': 5, 'penalty': 'l1', 'random_state': 314}</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col0\" class=\"data row1 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col1\" class=\"data row1 col1\" >1.0642</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col2\" class=\"data row1 col2\" >0.1127</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col3\" class=\"data row1 col3\" >0.4265</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col4\" class=\"data row1 col4\" >0.4288</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col5\" class=\"data row1 col5\" >{'class_weight': None, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'random_state': 314}</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col0\" class=\"data row2 col0\" >LGBMClassifier</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col1\" class=\"data row2 col1\" >15.9514</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col2\" class=\"data row2 col2\" >0.5525</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col3\" class=\"data row2 col3\" >0.7427</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col4\" class=\"data row2 col4\" >0.783</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col5\" class=\"data row2 col5\" >{'class_weight': 'balanced', 'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 200, 'random_state': 314}</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col0\" class=\"data row3 col0\" >LinearSVC</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col1\" class=\"data row3 col1\" >0.2563</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col2\" class=\"data row3 col2\" >0.013</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col3\" class=\"data row3 col3\" >0.7746</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col4\" class=\"data row3 col4\" >0.8819</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col5\" class=\"data row3 col5\" >{'C': 0.7, 'class_weight': 'balanced', 'max_iter': 5, 'random_state': 314}</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bc3d451e88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.6'></a>\n",
    "### 2.6 –í—ã–≤–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–≥–ª–∞—Å–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å `LinearSVC` –∏–º–µ–µ—Ç –Ω–∞–∏–ª—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ –ø–æ –º–µ—Ç—Ä–∏–∫–µ `F1-score` —Ç–∞–∫ –∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è.\n",
    "–î–∞–ª—å—à–µ —Å–ª–µ–¥—É–µ—Ç `LogisticRegression` –∏ `LGBMClassifier`. –≠—Ç–∏ –º–æ–¥–µ–ª–∏ –∏–¥—É—Ç –Ω–∞ —Ç–µ—Å—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.7'></a>\n",
    "### 2.7 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(model, X_test, y_test):\n",
    "    # Predict\n",
    "    start = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_time = time() - start\n",
    "    # F1-score\n",
    "    f1_score_metrics = f1_score(y_test, predictions)\n",
    "    \n",
    "    return [{\n",
    "            \"Model name\" : type(model).__name__,\n",
    "            \"Predict test time\" : round(predict_time, 4),\n",
    "            \"F1 test_score\" : round(f1_score_metrics, 4),\n",
    "            \"Parameters\" : model.get_params(model),\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results += get_test(logreg, X_test, y_test)\n",
    "test_results += get_test(lgb, X_test, y_test)\n",
    "test_results += get_test(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_completed(value):\n",
    "    color = 'orange' if value==True else 'black'\n",
    "    return 'color: %s'%color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in test_results:\n",
    "    f1_threshold = 0.75\n",
    "    if result[\"F1 test_score\"] >= f1_threshold:\n",
    "        result[\"Completed?\"] = True\n",
    "    else:\n",
    "        result[\"Completed?\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col0 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col1 {\n",
       "            : ;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col2 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col3 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col4 {\n",
       "            color:  orange;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col0 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col1 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col2 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col3 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col4 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col0 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col1 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col2 {\n",
       "            : ;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col3 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col4 {\n",
       "            color:  orange;\n",
       "        }</style><table id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model name</th>        <th class=\"col_heading level0 col1\" >Predict test time</th>        <th class=\"col_heading level0 col2\" >F1 test_score</th>        <th class=\"col_heading level0 col3\" >Parameters</th>        <th class=\"col_heading level0 col4\" >Completed?</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col1\" class=\"data row0 col1\" >0.005</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col2\" class=\"data row0 col2\" >0.7746</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col3\" class=\"data row0 col3\" >{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 5, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l1', 'random_state': 314, 'solver': 'warn', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col4\" class=\"data row0 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col0\" class=\"data row1 col0\" >LGBMClassifier</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col1\" class=\"data row1 col1\" >0.1426</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col2\" class=\"data row1 col2\" >0.7461</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col3\" class=\"data row1 col3\" >{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 200, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 314, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col4\" class=\"data row1 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col0\" class=\"data row2 col0\" >LinearSVC</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col1\" class=\"data row2 col1\" >0.004</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col2\" class=\"data row2 col2\" >0.7548</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col3\" class=\"data row2 col3\" >{'C': 0.7, 'class_weight': 'balanced', 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 5, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': 314, 'tol': 0.0001, 'verbose': 0}</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col4\" class=\"data row2 col4\" >True</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bc3d462d48>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_results(test_results).applymap(color_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. –í—ã–≤–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∫–∏ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è.\n",
    "–ù–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –º–æ–¥–µ–ª–∏ `LogisticRegression` –∏ `LinearSVC` —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –º–µ—Ç—Ä–∏–∫ –±–æ–ª—å—à–µ –ø–æ—Ä–æ–≥–æ–≤–æ–≥–æ $F1 = 0.75$.\n",
    "–£—á–∏—Ç—ã–≤–∞—è –∏—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º –±—É—Å—Ç–∏–Ω–≥–æ–º, –Ω–∞ –≤—ã–±–æ—Ä –∑–∞–∫–∞–∑—á–∏–∫—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ª—é–±–∞—è –∏–∑ –Ω–∏—Ö.\n",
    "–ù–æ –∏–∑-–∑–∞ –±–æ–ª—å—à–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ `F1-score` –±–æ–ª—å—à–µ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –æ—Ç–¥–∞—ë–º –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
