{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='green'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "\n",
    "Дмитрий, доброго дня! рад приветствовать тебя вновь)<br />\n",
    "(а дальше шаболонная обязательная часть, как ты заметил по другим спринтам)\n",
    "<br />\n",
    "Меня зовут Николай Шавлюго. <br />И на этом этапе твоего движения к новой профессии от меня будут комментарии по написанному коду. <br />Чтобы меньше \"мусорить эфир\" и чтобы максимально наглядно отделяться от основного кода, есть предложение условиться в некоторых обозначениях:<br /> <br />\n",
    "<u><b>ТАКОЙ ШРИФТ</b></u> - всегда начало комментария <br />\n",
    "<font color='green'>такой шрифт</font> - комментарии о том, что всё ОК <br/>\n",
    "<font color='orange'>такой шрифт</font> - комментарии о том, что всё ОК по результату,<br> однако есть на что обратить внимание в плане применения техник, или есть способы сделать более короткий или быстрый код <br/>\n",
    "<font color='red'>такой шрифт</font> - комментарии о том, что есть критичный момент, влияющий на бизнес-результат проекта.<br/>\n",
    "</font><br /><br />\n",
    "<font color='green'>Моей целью является не \"уличить\" в не знании, а просто высказать сверху твоих знаний - свой опыт, что бы ты мог использовать его для своего дальнейшего успеха) И очень здорово будет, если тебе удастся задавать вопросы, да и вообще - всячески доставать меня, если я по каким-то причинам не приму проект:) При этом, из своего опыта скажу, хорошо и важно, когда переписка ревьюера и студента - сохраняется на следующие проекты и даже на будущую практическую деятельность.<br>\n",
    "<BR> В ПУТЬ!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект для «Викишоп»\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание проекта\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    " * Постройте модель со значением метрики качества F1 не меньше 0.75.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Признаки:**  \n",
    "* `text` — текст комментария;\n",
    "* `toxic` — целевой признак.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Структура проекта\n",
    "<a href='#section1'></a>\n",
    "1. [Подготовка данных](#section1)  \n",
    "    1.1 [Первичный осмотр](#section1.1)  \n",
    "    1.2. [Очистка и лемматизация комментариев](#section1.2)   \n",
    "<a href='#section2'></a>  \n",
    "2. [Построение модели](#section2)  \n",
    "    2.1. [Подготовка данных к обучению](#section2.1)  \n",
    "    2.2. [LogisticRegression](#section2.2)  \n",
    "    2.3. [DecisionTreeClassifier](#section2.3)    \n",
    "    2.4. [LGBMClassifier](#section2.4)  \n",
    "    2.5. [LinearSVC](#section2.5)  \n",
    "    2.6. [Выводы обучения](#section2.6)  \n",
    "    2.7. [Тестирование](#section2.7)  \n",
    "<a href='#section3'></a>  \n",
    "3. [Выводы исследования](#section3)\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# String\n",
    "import re\n",
    "import string\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# Инструменты\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "from time import time\n",
    "# Метрики\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score,  f1_score,  roc_auc_score, roc_curve, make_scorer\n",
    "# Графика\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(\"paper\")\n",
    "# nltk\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "punctuation = string.punctuation \n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1.1'></a>\n",
    "### 1.1 Первичный осмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.83"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['toxic'].value_counts())\n",
    "\n",
    "class_ratio = round(data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1], 2)\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем сильный дисбаланс классов: `1 : 8.83`.  \n",
    "Воспользуемся балансировкой весов обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текст перед этим и разобьём на выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='green'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "Ок. данные на базе)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1.2'></a>\n",
    "### 1.2 Очистка и лемматизация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначально пользовались `Mystem` из библиотеки `pymystem3`, однако процесс очистки и лемматизации улетел за полчаса => решено было использовать `WordNetLemmatizer` и функции `map`, `filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_of_text(text):\n",
    "    tokens = [word for w in sent_tokenize(text) for word in word_tokenize(w)]\n",
    "    # Remove punctuation inside words\n",
    "    tokens = list(filter(lambda token: token not in punctuation, tokens)) \n",
    "    # Remove stopwords\n",
    "    tokens = list(filter(lambda token: token.lower() not in stop_words, tokens))\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search(\"[a-zA-Z]\", token):\n",
    "            filtered_tokens.append(token)\n",
    "    # lemmatize text\n",
    "    filtered_tokens = list(map(lambda token: wordnet_lemmatizer.lemmatize(token.lower()), filtered_tokens)) \n",
    "    filtered_tokens = list(filter(lambda token: token not in punctuation, filtered_tokens))\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 44s, sys: 780 ms, total: 4min 45s\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data[\"clear_text\"] = data[\"text\"].map(preparation_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour 'm seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man 'm really trying edit war 's guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't make real suggestion improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                         clear_text\n",
       "0      0  explanation edits made username hardcore metal...\n",
       "1      0  d'aww match background colour 'm seemingly stu...\n",
       "2      0  hey man 'm really trying edit war 's guy const...\n",
       "3      0  ca n't make real suggestion improvement wonder...\n",
       "4      0                   sir hero chance remember page 's"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(\"text\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_valid_test_split(data : pd.DataFrame, target_column : str, proportions=[0.6, 0.2, 0.2]):\n",
    "#     \"\"\"\n",
    "#     Function splits by train, validation, test parts income dataframe.\n",
    "#     In:\n",
    "#         df : pandas.DataFrame() - income dataframe.\n",
    "#         proportions : list() - list of proportions values to split method.\n",
    "#     \"\"\"\n",
    "#     if sum([*proportions]) != 1:\n",
    "#         raise AttributeError('Wrong \"proportions\" values. Sum of \"proportions\" values > 1.0. Must be equal to 1.0.')\n",
    "#     data_list = [train, valid, test] = np.split(\n",
    "#         data.sample(frac=1, random_state=314), \n",
    "#         [int(proportions[0] * len(data)), int(sum(proportions[:2]) * len(data))]\n",
    "#     )\n",
    "#     features, targets = list(), list()\n",
    "#     for data in data_list:\n",
    "#         features.append(data.drop(target_column, axis=1))\n",
    "#         targets.append(data[target_column])\n",
    "#     return [*features, *targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"toxic\"]\n",
    "features = data.drop(\"toxic\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shapes || (127656, 1) || (31915, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.2, random_state=314)\n",
    "print(\"X_shapes\", X_train.shape, X_test.shape, sep=' || ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>71831</td>\n",
       "      <td>think mucha lucha homosexual show 've ever wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38139</td>\n",
       "      <td>swore well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6079</td>\n",
       "      <td>corrected thee countless ahs china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31624</td>\n",
       "      <td>n't offended 'm sorry keep fixing indentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129677</td>\n",
       "      <td>previous full lupine state allowed lift ton sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clear_text\n",
       "71831   think mucha lucha homosexual show 've ever wit...\n",
       "38139                                          swore well\n",
       "6079                   corrected thee countless ahs china\n",
       "31624   n't offended 'm sorry keep fixing indentation ...\n",
       "129677  previous full lupine state allowed lift ton sa..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные на базе😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='green'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "Точно:)\n",
    "    \n",
    "При этом - важная часть работы сделана - чистка и лемматизация! <br>\n",
    "Это как шашлык готовить: сначала важный этап маринада, а потом приготовление:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.1'></a>\n",
    "### 2.1 Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = X_train[\"clear_text\"].values.astype('U')\n",
    "test_corpus = X_test[\"clear_text\"].values.astype('U')\n",
    "# Vectorizer\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "# Fit_trasform train & transform others.\n",
    "X_train = count_tf_idf.fit_transform(train_corpus)\n",
    "X_test = count_tf_idf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='green'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "ок, в такой последовательности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, X, y, param_grid, scoring):\n",
    "    model_cv = GridSearchCV(\n",
    "        model(),\n",
    "        param_grid = param_grid,\n",
    "        cv = 4,\n",
    "        scoring = scoring,\n",
    "        n_jobs = -1,\n",
    "        verbose = 10,\n",
    "        return_train_score = True\n",
    "    )\n",
    "    # Подбор гиперпараметров\n",
    "    model_cv = model_cv.fit(X, y)\n",
    "    # Best etimator\n",
    "    model_best = model_cv.best_estimator_\n",
    "    cv_results = model_cv.cv_results_\n",
    "\n",
    "    # Train\n",
    "    start_time = time()\n",
    "    model_best.fit(X, y)\n",
    "    train_time = time() - start_time\n",
    "    # Predict\n",
    "    start_time = time()\n",
    "    predictions = model_best.predict(X)\n",
    "    predict_time = time() - start_time\n",
    "    # F1-score metrics\n",
    "    f1_score_metrics = f1_score(y, predictions)\n",
    "    # Result list\n",
    "    rlt = [{\n",
    "        \"Model name\" : type(model_best).__name__,\n",
    "        \"Train time\" : round(train_time, 4),\n",
    "        \"Predict time\" : round(predict_time, 4),\n",
    "        \"F1 train_score\" : model_cv.best_score_.round(4),\n",
    "        \"F1 predict_score\" : round(f1_score_metrics, 4),\n",
    "        \"Parameters\" : model_cv.best_params_\n",
    "    }]\n",
    "    return model_best, model_cv.best_params_, rlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.2'></a>\n",
    "### 2.2 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_params_dict = {\n",
    "    \"random_state\" : [314],\n",
    "    \"penalty\" : [\"l1\"],\n",
    "    \"class_weight\" : [None, \"balanced\"],\n",
    "    \"max_iter\" : range(5, 20, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  64 | elapsed:   33.0s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'LogisticRegression',\n",
       " 'Train time': 0.392,\n",
       " 'Predict time': 0.011,\n",
       " 'F1 train_score': 0.7682,\n",
       " 'F1 predict_score': 0.7955,\n",
       " 'Parameters': {'class_weight': None,\n",
       "  'max_iter': 5,\n",
       "  'penalty': 'l1',\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg, logreg_params, logreg_result = cross_validation(\n",
    "    model = LogisticRegression,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = logreg_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += logreg_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.3'></a>\n",
    "### 2.3 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params_dict = {\n",
    "    \"random_state\" : [314],\n",
    "    \"max_depth\" : range(2, 4),\n",
    "    \"min_samples_split\" : range(2, 4),\n",
    "    \"min_samples_leaf\" : range(2, 4),\n",
    "    \"class_weight\" : [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  64 | elapsed:  1.8min remaining:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'DecisionTreeClassifier',\n",
       " 'Train time': 1.0642,\n",
       " 'Predict time': 0.1127,\n",
       " 'F1 train_score': 0.4265,\n",
       " 'F1 predict_score': 0.4288,\n",
       " 'Parameters': {'class_weight': None,\n",
       "  'max_depth': 3,\n",
       "  'min_samples_leaf': 2,\n",
       "  'min_samples_split': 2,\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree, tree_params, tree_result = cross_validation(\n",
    "    model = DecisionTreeClassifier,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = tree_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += tree_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.4'></a>\n",
    "### 2.4 LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_dict = {\n",
    "    \"random_state\" : [314],\n",
    "    \"learning_rate\" : [0.25, 0.3],\n",
    "    \"n_estimators\" : [150, 200, 250],\n",
    "    \"max_depth\" : range(3, 5),\n",
    "    \"class_weight\" : [\"balanced\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  48 | elapsed:  4.6min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  48 | elapsed:  5.0min remaining:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  5.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'LGBMClassifier',\n",
       " 'Train time': 15.9514,\n",
       " 'Predict time': 0.5525,\n",
       " 'F1 train_score': 0.7427,\n",
       " 'F1 predict_score': 0.783,\n",
       " 'Parameters': {'class_weight': 'balanced',\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 4,\n",
       "  'n_estimators': 200,\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb, lgb_params, lgb_result = cross_validation(\n",
    "    model = LGBMClassifier,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = lgb_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += lgb_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.5'></a>\n",
    "### 2.5 LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params_dict = {\n",
    "    \"C\" : [x / 10 for x in range(1, 21)],\n",
    "    \"max_iter\" : [5, 7, 10, 25, 100],\n",
    "    \"class_weight\" : [\"balanced\"],\n",
    "    \"random_state\" : [314]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model name': 'LinearSVC',\n",
       " 'Train time': 0.2563,\n",
       " 'Predict time': 0.013,\n",
       " 'F1 train_score': 0.7746,\n",
       " 'F1 predict_score': 0.8819,\n",
       " 'Parameters': {'C': 0.7,\n",
       "  'class_weight': 'balanced',\n",
       "  'max_iter': 5,\n",
       "  'random_state': 314}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svc, svc_params_dict, svc_result = cross_validation(\n",
    "    model = LinearSVC,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    param_grid = svc_params_dict,\n",
    "    scoring = scorer\n",
    ")\n",
    "\n",
    "results += svc_result\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_results(results : list):    \n",
    "    return (pd.DataFrame(results)\n",
    "        .style\n",
    "        .highlight_min(color='orange')\n",
    "        .highlight_max(color='lightgreen')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col2 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col3 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col4 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col1 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col2 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col1 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col3 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col4 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model name</th>        <th class=\"col_heading level0 col1\" >Train time</th>        <th class=\"col_heading level0 col2\" >Predict time</th>        <th class=\"col_heading level0 col3\" >F1 train_score</th>        <th class=\"col_heading level0 col4\" >F1 predict_score</th>        <th class=\"col_heading level0 col5\" >Parameters</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col1\" class=\"data row0 col1\" >0.392</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col2\" class=\"data row0 col2\" >0.011</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col3\" class=\"data row0 col3\" >0.7682</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col4\" class=\"data row0 col4\" >0.7955</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow0_col5\" class=\"data row0 col5\" >{'class_weight': None, 'max_iter': 5, 'penalty': 'l1', 'random_state': 314}</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col0\" class=\"data row1 col0\" >DecisionTreeClassifier</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col1\" class=\"data row1 col1\" >1.0642</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col2\" class=\"data row1 col2\" >0.1127</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col3\" class=\"data row1 col3\" >0.4265</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col4\" class=\"data row1 col4\" >0.4288</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow1_col5\" class=\"data row1 col5\" >{'class_weight': None, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'random_state': 314}</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col0\" class=\"data row2 col0\" >LGBMClassifier</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col1\" class=\"data row2 col1\" >15.9514</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col2\" class=\"data row2 col2\" >0.5525</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col3\" class=\"data row2 col3\" >0.7427</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col4\" class=\"data row2 col4\" >0.783</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow2_col5\" class=\"data row2 col5\" >{'class_weight': 'balanced', 'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 200, 'random_state': 314}</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col0\" class=\"data row3 col0\" >LinearSVC</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col1\" class=\"data row3 col1\" >0.2563</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col2\" class=\"data row3 col2\" >0.013</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col3\" class=\"data row3 col3\" >0.7746</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col4\" class=\"data row3 col4\" >0.8819</td>\n",
       "                        <td id=\"T_bd83b2ec_90c0_11eb_a015_d2a3e05ef35crow3_col5\" class=\"data row3 col5\" >{'C': 0.7, 'class_weight': 'balanced', 'max_iter': 5, 'random_state': 314}</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bc3d451e88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.6'></a>\n",
    "### 2.6 Выводы обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно результатам обучения модель `LinearSVC` имеет наилучшие значения как по метрике `F1-score` так и по времени обучения.\n",
    "Дальше следует `LogisticRegression` и `LGBMClassifier`. Эти модели идут на тест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='green'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "Дмитрий, задачка такая, что часто и железо не тянет, больше на терпение:)<br>\n",
    "Интересные исследования по применению разных моделей ты провёл!<br>\n",
    "Однозначно видно, что ты понимаешь что делать.<br>\n",
    "И если потребуется на практике - реально сможешь применить. А это тот результат, что и нужен на обучении.<br>\n",
    "Если же говорить о потенциале по точности модели, то тут он, в том числе, кроется в исследовании самих фраз: длинные/короткие (возможно даже как фактор внести размер фразы - ну или поисследовать этот момент), установить минимальное количество букв во фразе... <br>\n",
    "      \n",
    "Всё чётко у тебя и толково!<br>    \n",
    "Спасибо) УСПЕШНОГО И ДАЛЬШЕ ОБУЧЕНИЯ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.7'></a>\n",
    "### 2.7 Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(model, X_test, y_test):\n",
    "    # Predict\n",
    "    start = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_time = time() - start\n",
    "    # F1-score\n",
    "    f1_score_metrics = f1_score(y_test, predictions)\n",
    "    \n",
    "    return [{\n",
    "            \"Model name\" : type(model).__name__,\n",
    "            \"Predict test time\" : round(predict_time, 4),\n",
    "            \"F1 test_score\" : round(f1_score_metrics, 4),\n",
    "            \"Parameters\" : model.get_params(model),\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results += get_test(logreg, X_test, y_test)\n",
    "test_results += get_test(lgb, X_test, y_test)\n",
    "test_results += get_test(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_completed(value):\n",
    "    color = 'orange' if value==True else 'black'\n",
    "    return 'color: %s'%color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in test_results:\n",
    "    f1_threshold = 0.75\n",
    "    if result[\"F1 test_score\"] >= f1_threshold:\n",
    "        result[\"Completed?\"] = True\n",
    "    else:\n",
    "        result[\"Completed?\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col0 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col1 {\n",
       "            : ;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col2 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col3 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col4 {\n",
       "            color:  orange;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col0 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col1 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col2 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col3 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col4 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col0 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col1 {\n",
       "            background-color:  orange;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col2 {\n",
       "            : ;\n",
       "            : ;\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col3 {\n",
       "            color:  black;\n",
       "        }    #T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col4 {\n",
       "            color:  orange;\n",
       "        }</style><table id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model name</th>        <th class=\"col_heading level0 col1\" >Predict test time</th>        <th class=\"col_heading level0 col2\" >F1 test_score</th>        <th class=\"col_heading level0 col3\" >Parameters</th>        <th class=\"col_heading level0 col4\" >Completed?</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col0\" class=\"data row0 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col1\" class=\"data row0 col1\" >0.005</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col2\" class=\"data row0 col2\" >0.7746</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col3\" class=\"data row0 col3\" >{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 5, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l1', 'random_state': 314, 'solver': 'warn', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow0_col4\" class=\"data row0 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col0\" class=\"data row1 col0\" >LGBMClassifier</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col1\" class=\"data row1 col1\" >0.1426</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col2\" class=\"data row1 col2\" >0.7461</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col3\" class=\"data row1 col3\" >{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.3, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 200, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 314, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow1_col4\" class=\"data row1 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col0\" class=\"data row2 col0\" >LinearSVC</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col1\" class=\"data row2 col1\" >0.004</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col2\" class=\"data row2 col2\" >0.7548</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col3\" class=\"data row2 col3\" >{'C': 0.7, 'class_weight': 'balanced', 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 5, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': 314, 'tol': 0.0001, 'verbose': 0}</td>\n",
       "                        <td id=\"T_bdb049b8_90c0_11eb_9ec1_d2a3e05ef35crow2_col4\" class=\"data row2 col4\" >True</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bc3d462d48>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_results(test_results).applymap(color_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. Выводы исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате построена модель оценки токсичности комментария.\n",
    "Наилучшие результаты показывают модели `LogisticRegression` и `LinearSVC` со значениями метрик больше порогового $F1 = 0.75$.\n",
    "Учитывая их преимущества в скорости обучения перед градиентным бустингом, на выбор заказчику рекомендуется любая из них.\n",
    "Но из-за большего значения метрики `F1-score` большее предпочтение отдаём логистической регрессии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
